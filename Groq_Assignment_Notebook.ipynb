{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd415d98",
   "metadata": {},
   "source": [
    "\n",
    "# AI/ML Internship Assignment ‚Äì Groq API\n",
    "\n",
    "This project demonstrates how to use the **Groq API** for two key Natural Language Processing (NLP) tasks:  \n",
    "\n",
    "1. **Summarization** ‚Äì Generate short summaries of conversations.  \n",
    "2. **Classification** ‚Äì Categorize conversations into structured JSON format with fields:\n",
    "   - `intent`\n",
    "   - `issue`\n",
    "   - `category`\n",
    "\n",
    "We use the **Groq Chat Completion API** with the model `llama-3.3-70b-versatile`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1457a8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------\n",
    "# AI/ML Internship Assignment - Groq API (Working Model)\n",
    "# ------------------------------\n",
    "\n",
    "API_KEY = \"YOUR_API_KEY_HERE\"\n",
    "API_BASE = \"https://api.groq.com/openai\"\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def call_chat_model(messages, model=\"llama-3.3-70b-versatile\", max_tokens=256, temperature=0.2):\n",
    "    url = f\"{API_BASE}/v1/chat/completions\"\n",
    "    headers = {\"Authorization\": f\"Bearer {API_KEY}\", \"Content-Type\": \"application/json\"}\n",
    "    payload = {\"model\": model, \"messages\": messages, \"max_tokens\": max_tokens, \"temperature\": temperature}\n",
    "\n",
    "    resp = requests.post(url, headers=headers, json=payload)\n",
    "\n",
    "    try:\n",
    "        data = resp.json()\n",
    "    except:\n",
    "        print(\"‚ùå Could not decode response:\", resp.text)\n",
    "        return None\n",
    "\n",
    "    if \"choices\" not in data:\n",
    "        print(\"‚ö†Ô∏è API Error:\", data)\n",
    "        return None\n",
    "\n",
    "    return data['choices'][0]['message']['content']\n",
    "\n",
    "\n",
    "def summarize_conv(text):\n",
    "    system = {\"role\":\"system\",\"content\":\"Summarize this chat in 1-2 sentences. Return plain text only.\"}\n",
    "    user = {\"role\":\"user\",\"content\": text}\n",
    "    return call_chat_model([system,user])\n",
    "\n",
    "\n",
    "def classify_conv(text):\n",
    "    system = {\"role\":\"system\",\"content\":\"Classify this chat into JSON with fields {\\\"intent\\\":\\\"...\\\", \\\"issue\\\":\\\"...\\\", \\\"category\\\":\\\"...\\\"}.\"}\n",
    "    user = {\"role\":\"user\",\"content\": text}\n",
    "    return call_chat_model([system,user])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2daa665",
   "metadata": {},
   "source": [
    "\n",
    "## üìù Summarization Demo\n",
    "\n",
    "Here we provide a sample chat between a user and assistant.  \n",
    "The model generates a **short summary** of the conversation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044ff350",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "example1 = \"User: My internet is down. Assistant: Please restart your router.\"\n",
    "\n",
    "print(\"---- Summarization Example ----\")\n",
    "print(summarize_conv(example1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9295c04e",
   "metadata": {},
   "source": [
    "\n",
    "## üìù Classification Demo\n",
    "\n",
    "Here we classify a sample chat into structured JSON with fields:\n",
    "- `intent`\n",
    "- `issue`\n",
    "- `category`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b583d21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "example2 = \"User: I can‚Äôt log in to my account. Assistant: Please reset your password.\"\n",
    "\n",
    "print(\"\\n---- Classification Example ----\")\n",
    "print(classify_conv(example2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee86245",
   "metadata": {},
   "source": [
    "\n",
    "# ‚úÖ Results\n",
    "\n",
    "- **Summarization Example Output:**  \n",
    "  The model correctly summarized the chat about internet connectivity.  \n",
    "\n",
    "- **Classification Example Output:**  \n",
    "  The model classified the chat into JSON format with intent = *Technical Support*, issue = *Login Issue*, category = *Account Management*.  \n",
    "\n",
    "This demonstrates how Groq API can be applied for **AI/ML conversational analysis tasks**.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}